{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mymodels\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = '../'\n",
    "dataset_folder = main_folder + 'dataset_tfrecord_small/'\n",
    "dataset2_folder = main_folder + 'dataset2/'\n",
    "logs_folder = main_folder + 'logs/'\n",
    "checkpoints_folder = main_folder + 'checkpoints_sect1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor(dataset):\n",
    "    tensor= []\n",
    "    for batch in dataset.take(-1):\n",
    "        batch = np.array(batch)\n",
    "        tensor.append(batch)\n",
    "\n",
    "    tensor = np.array(tensor)\n",
    "    return tensor\n",
    "\n",
    "def load_tfrecord(filename, dataset_type=tf.int32):\n",
    "    parse_tensor = lambda x: tf.io.parse_tensor(x, dataset_type)\n",
    "    return tf.data.TFRecordDataset(filename).map(parse_tensor)\n",
    "    \n",
    "def make_tf_dataset(X, y):\n",
    "    dataset = tf.data.Dataset.zip((X, y))\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_tfrecord(dataset_folder + 'train_image.tfrecord', dataset_type=tf.double)\n",
    "y = load_tfrecord(dataset_folder + 'train_label.tfrecord', dataset_type=tf.int64)\n",
    "\n",
    "X_test = load_tfrecord(dataset_folder + 'test_image.tfrecord', dataset_type=tf.double)\n",
    "y_test = load_tfrecord(dataset_folder + 'test_label.tfrecord', dataset_type=tf.int64)\n",
    "\n",
    "train_dataset = make_tf_dataset(X, y)\n",
    "val_dataset = make_tf_dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 128, 1) (128, 10)\n"
     ]
    }
   ],
   "source": [
    "for i, a in enumerate(train_dataset.take(1)):\n",
    "    x,y = a\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 126, 126, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 63, 63, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 57600)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               7372928   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,400,130\n",
      "Trainable params: 7,400,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "weights = checkpoints_folder + 'sect1_epoch_100.weights.h5'\n",
    "model = mymodels.sect1()\n",
    "model.compile()\n",
    "model.load_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_images(X_train_canvas, batch):\n",
    "    X_cropped = []\n",
    "    crop_amount = 32\n",
    "    base_grace = 5\n",
    "\n",
    "    small_data = X_train_canvas #[:100]\n",
    "\n",
    "    for i in range(small_data.shape[0]):\n",
    "        grace = base_grace\n",
    "\n",
    "        image = small_data[i]\n",
    "        coords = model.predict(image.reshape(1, 128, 128, 1))\n",
    "        x = int(coords[0][0])\n",
    "        y = int(coords[0][1])\n",
    "        if x > 128-crop_amount-grace:\n",
    "            x = 128-crop_amount-grace\n",
    "        if x < grace:\n",
    "            x = grace\n",
    "        if y > 128-crop_amount-grace:\n",
    "            y = 128-crop_amount-grace\n",
    "        if y < grace:\n",
    "            y = grace\n",
    "        \n",
    "        cropped_image = image[y-grace:y+crop_amount+grace, x-grace:x+crop_amount+grace]\n",
    "\n",
    "        if cropped_image.shape != (42,42,1):\n",
    "            print(f\"Error: {cropped_image.shape}\")\n",
    "            print(x,y)\n",
    "            plt.imshow(cropped_image)\n",
    "            plt.show()\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "        X_cropped.append(cropped_image)\n",
    "        print(f\"\\rNum: {i+1} / {small_data.shape[0]} Batch: {batch} \", end='')\n",
    "\n",
    "    X_cropped = np.array(X_cropped)\n",
    "    return X_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    value = value.flatten()  # Flatten the entire batch into a 1D list\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))  # Convert to list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def example_test(image, label):\n",
    "    feature = {\n",
    "        'image': _bytes_feature(image),\n",
    "        'label': _bytes_feature(label)\n",
    "    }\n",
    "    #print(f'feature: {feature[\"label\"]}')\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "def write_in_batches(data, filename, batch_size=100):\n",
    "    #print(data.shape)\n",
    "    record_file = filename\n",
    "    with tf.io.TFRecordWriter(record_file) as writer:\n",
    "        # Iterate through the dataset in batches\n",
    "        for i, set in enumerate(data.take(-1)):\n",
    "            images, labels = set\n",
    "            batch = np.array(images)\n",
    "            #batch = crop_images(batch, i)\n",
    "            serialized_image = tf.io.serialize_tensor(batch).numpy()\n",
    "            \n",
    "            labels = np.array(labels)\n",
    "            labels_unonehot = np.argmax(labels, axis=-1)\n",
    "            labels_class_indices = tf.io.serialize_tensor(labels_unonehot).numpy()\n",
    "\n",
    "            tf_example = example_test(serialized_image, labels_class_indices)\n",
    "            writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_in_batches(train_dataset, 'train_dataset_cropped.tfrecord')\n",
    "write_in_batches(val_dataset, 'test_dataset_cropped.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
